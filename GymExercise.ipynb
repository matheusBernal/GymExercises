{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfPaftGgBDzDB8HVp4SmvB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheusBernal/GymExercises/blob/main/GymExercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project uses data from gym members' exercise routines, physical attributes, and other fitness metrics. I will use this information to create two algorithms: one to classify the experience level and workout type, and another to perform regression to predict the calories burned."
      ],
      "metadata": {
        "id": "WvHKCOGABujn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install sklearn\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install scikeras tensorflow keras --upgrade"
      ],
      "metadata": {
        "id": "E6T7zdSBZQWF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40970525-56bd-491b-85e1-76e23fa2edb0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, keras, tensorflow, scikeras\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.7.0 scikeras-0.13.0 tensorboard-2.18.0 tensorflow-2.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorflow"
                ]
              },
              "id": "79fde38942b94296b0a89ee6d0a82972"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression,Ridge\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,mean_squared_error,mean_absolute_error\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "hTe81loU9TP2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "a143e62a-18f0-4833-9d90-2437fb3097f5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Circle' from 'keras.src.losses.losses' (/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-052c59bf2525>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0munflatten_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegressorTargetEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_loss_get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/api/losses/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalFocalCrossentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalHinge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCircle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCosineSimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Circle' from 'keras.src.losses.losses' (/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gym_members_exercise_tracking.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "3C-NAC1d-0dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['Age', 'Gender', 'Weight (kg)', 'Height (m)', 'Max_BPM', 'Avg_BPM','Resting_BPM', 'Session_Duration (hours)','Fat_Percentage', 'Water_Intake (liters)','Workout_Frequency (days/week)', 'BMI','Calories_Burned','Experience_Level','Workout_Type']]"
      ],
      "metadata": {
        "id": "PN-aDzT8_CKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7yfJ7bs4DP8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "7oiE4Zu3Hn2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "lv8Hc_kYtFYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm going to divide my data into three groups: workout type, experience level, and calories burned. First, I will create the regression model for calories burned. After that, I will create the classification for experience level, and finally, I will create the classification for workout type."
      ],
      "metadata": {
        "id": "uJ3W9NQPylOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #First i'll need to using the label encoder on column Gender to pass on train regression\n",
        "genderLabel = LabelEncoder()\n",
        "df_preprocessing = df\n",
        "df_preprocessing['Gender'] = genderLabel.fit_transform(df_preprocessing['Gender'])\n",
        "df_preprocessing"
      ],
      "metadata": {
        "id": "9ORtBPBMESXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's examine the correlation between the variables and calories burned and select the strongest variables (positive or negative) to create our regression model. If the variable is greater than 0.5, it is strongly positive (variable > 0.5). If the variable is less than -0.5, it is strongly negative (variable < 0.5). And if the variable is close to or equal to zero, its strength is considered null."
      ],
      "metadata": {
        "id": "tEzvt-AgI3Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocessing.iloc[:,:-2].corr()"
      ],
      "metadata": {
        "id": "HDmG3O9YIRi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(df_preprocessing.iloc[:,:-2].corr(),annot=True)"
      ],
      "metadata": {
        "id": "Rp91HbHMIwyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_cb = df_preprocessing[['Session_Duration (hours)','Fat_Percentage','Workout_Frequency (days/week)']].values\n",
        "y_cb = df_preprocessing['Calories_Burned'].values"
      ],
      "metadata": {
        "id": "iakWaNIiLIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_cb_train,x_cb_test,y_cb_train,y_cb_test = train_test_split(x_cb,y_cb,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "hkrNP8BTMH21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "linear_model = model.fit(x_cb_train,y_cb_train)\n",
        "prediction_train = linear_model.predict(x_cb_train)\n",
        "prediction_test = linear_model.predict(x_cb_test)\n",
        "print(linear_model.coef_,linear_model.intercept_)\n",
        "print('Train score:',round(linear_model.score(x_cb_train,y_cb_train),3)*100)\n",
        "print('Test score:',round(linear_model.score(x_cb_test,y_cb_test),3)*100)\n",
        "print(mean_squared_error(y_cb_train,prediction_train),mean_squared_error(y_cb_test,prediction_test))\n",
        "print(mean_absolute_error(y_cb_train,prediction_train),mean_squared_error(y_cb_test,prediction_test))"
      ],
      "metadata": {
        "id": "0rEjRCHPMV71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function that our LineaRegression create is Y = 694.51683961 * X  -4.95866653 * Z -13.94390992 * W + 203.9242449799383. And the score on the train's data is 83% and tests data is 84,5%"
      ],
      "metadata": {
        "id": "6Llg831mNEIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=x_cb_train[:, 0], y=y_cb_train)\n",
        "sns.scatterplot(x=x_cb_train[:, 0], y=prediction_train)\n",
        "plt.legend(['Train','Train prediction'])\n",
        "plt.xlabel('Session_Duration (hours)')\n",
        "plt.ylabel('Calories Burned')\n",
        "plt.title('Calories Burned vs. Session Duration (hours)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cD8a1oJiQQSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=x_cb_train[:, 1], y=y_cb_train)\n",
        "sns.scatterplot(x=x_cb_train[:, 1], y=prediction_train)\n",
        "plt.legend(['Train','Train prediction'])\n",
        "plt.xlabel('Fat Percentage')\n",
        "plt.ylabel('Calories Burned')\n",
        "plt.title('Calories Burned vs. Fat_Percentage')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l1tJlvsPQbaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=x_cb_train[:, 2], y=y_cb_train)\n",
        "sns.scatterplot(x=x_cb_train[:, 2], y=prediction_train)\n",
        "plt.legend(['Train','Train prediction'])\n",
        "plt.xlabel('Workout_Frequency (days/week)')\n",
        "plt.ylabel('Calories Burned')\n",
        "plt.title('Calories Burned vs. Workout_Frequency (days/week)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ivlv_lh3Q71B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=x_cb_test[:, 0], y=y_cb_test)\n",
        "sns.scatterplot(x=x_cb_test[:, 0], y=prediction_test)\n",
        "plt.legend(['Train','Train prediction'])\n",
        "plt.xlabel('Session_Duration (hours)')\n",
        "plt.ylabel('Calories Burned')\n",
        "plt.title('Calories Burned vs. Session Duration (hours)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Teryy43RNss3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=x_cb_test[:, 1], y=y_cb_test)\n",
        "sns.scatterplot(x=x_cb_test[:, 1], y=prediction_test)\n",
        "plt.legend(['Test','Test prediction'])\n",
        "plt.xlabel('Fat Percentage')\n",
        "plt.ylabel('Calories Burned')\n",
        "plt.title('Calories Burned vs. Fat_Percentage')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cV67JTcwPLME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=x_cb_test[:, 2], y=y_cb_test)\n",
        "sns.scatterplot(x=x_cb_test[:, 2], y=prediction_test)\n",
        "plt.legend(['Test','Test prediction'])\n",
        "plt.xlabel('Workout_Frequency (days/week)')\n",
        "plt.ylabel('Calories Burned')\n",
        "plt.title('Calories Burned vs. Workout_Frequency (days/week)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y1xqMWFZPi6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try with Ridge function"
      ],
      "metadata": {
        "id": "sJr23nWhV_6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge()\n",
        "ridge_model = ridge.fit(x_cb_train,y_cb_train)\n",
        "prediction_train = ridge_model.predict(x_cb_train)\n",
        "prediction_test = ridge_model.predict(x_cb_test)\n",
        "print(ridge_model.coef_,ridge_model.intercept_)\n",
        "print('Train score:',round(ridge_model.score(x_cb_train,y_cb_train),3)*100)\n",
        "print('Test score:',round(ridge_model.score(x_cb_test,y_cb_test),3)*100)\n"
      ],
      "metadata": {
        "id": "i-8mcKsiKRKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Th function that our Ridge create is Y = 679.85919549 * X -5.22780541 * Z -11.40942128 * W + 220.70894588408976. And the score on the train's data is 83% and tests data is 84,5%. So we don't have any difference between the Ridge and the Linear Model in fact"
      ],
      "metadata": {
        "id": "67lx1yfiW1Yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's make the Experience Level classification"
      ],
      "metadata": {
        "id": "Ey3lhm34YU-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_preprocessing.shape"
      ],
      "metadata": {
        "id": "f-p9PxCJhV0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First, I will use the OneHotEncoder and ColumnTransformer on the Gender column. Finally, I will apply StandardScaler to prepare the data for the classification model.\n",
        "OneHotEncoderGender = ColumnTransformer([('Gender',OneHotEncoder(),[1])],remainder='passthrough')\n",
        "x_experiênce_level = df_preprocessing.iloc[:,:-2].values\n",
        "y_experience_level = df_preprocessing.iloc[:,-2].values\n",
        "x_experiênce_level = OneHotEncoderGender.fit_transform(x_experiênce_level)\n",
        "x_experiênce_level = StandardScaler().fit_transform(x_experiênce_level)\n",
        "x_experiênce_level.shape"
      ],
      "metadata": {
        "id": "fuG9henAevJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Let's try using some methods to create our classification. First let's try use Gaussian. Accuracy 88%"
      ],
      "metadata": {
        "id": "3WFRf2cqjgw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gaussianModel = GaussianNB()\n",
        "x_experiênce_level_train,x_experiênce_level_test,y_experience_level_train,y_experience_level_test = train_test_split(x_experiênce_level,y_experience_level,test_size=0.2,random_state=0)\n",
        "gaussian_model = gaussianModel.fit(x_experiênce_level_train,y_experience_level_train)"
      ],
      "metadata": {
        "id": "zIYQvjTXjgQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_train_level = gaussian_model.predict(x_experiênce_level_train)\n",
        "prediction_test_level = gaussian_model.predict(x_experiênce_level_test)\n",
        "\n",
        "print('Train score:',round(accuracy_score(y_experience_level_train,prediction_train_level),3)*100)\n",
        "print('Test score:',round(accuracy_score(y_experience_level_test,prediction_test_level),3)*100)"
      ],
      "metadata": {
        "id": "e-2u0CNwnff7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_experience_level_train,prediction_train_level),confusion_matrix(y_experience_level_test,prediction_test_level)"
      ],
      "metadata": {
        "id": "AEldP95Mn4St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_experience_level_train,prediction_train_level),classification_report(y_experience_level_test,prediction_test_level))"
      ],
      "metadata": {
        "id": "oRQKZDnzoHWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=gaussianModel, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(x_experiênce_level_train, y_experience_level_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)"
      ],
      "metadata": {
        "id": "lOWA9Q6-otbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Let's use the Decision Tree and forward I'll use the grid Search to create the algorithm. Accuracy: 87%"
      ],
      "metadata": {
        "id": "dSxKGo0Apz9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_experiênce_level_train, y_experience_level_train)\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "r2V8A7CFwp-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decisionTreeXpLevel = DecisionTreeClassifier(criterion = 'gini', max_depth = 30, max_features= None, min_samples_leaf = 1, min_samples_split= 10)\n",
        "decisionTreeXpLevel_model = decisionTreeXpLevel.fit(x_experiênce_level_train,y_experience_level_train)\n",
        "print('Train score: ',accuracy_score(y_experience_level_train,decisionTreeXpLevel_model.predict(x_experiênce_level_train)))\n",
        "print('Test score: ',accuracy_score(y_experience_level_test,decisionTreeXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "_6Y97YdUq_Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the tree"
      ],
      "metadata": {
        "id": "ktmwhRhDI2Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure,ax = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
        "tree.plot_tree(\n",
        "    decisionTreeXpLevel_model,\n",
        "    filled=True,\n",
        "    ax=ax\n",
        ")"
      ],
      "metadata": {
        "id": "GkQ3407LuJHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_experience_level_train,decisionTreeXpLevel_model.predict(x_experiênce_level_train)),confusion_matrix(y_experience_level_test,decisionTreeXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "ZjF3AzV1sJyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_experience_level_train,decisionTreeXpLevel_model.predict(x_experiênce_level_train)),classification_report(y_experience_level_test,decisionTreeXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "MxN9kL1nsNh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I'm going to use the random forest algoritm.Accuracy 88%"
      ],
      "metadata": {
        "id": "cio2dVzVs5HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 5],\n",
        "    'max_features': [None, 'sqrt', 'log2'],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_experiênce_level_train, y_experience_level_train)\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "Ii6wFWdmsZOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomForestXpLevel = RandomForestClassifier(criterion = 'entropy', max_features = 'log2', min_samples_leaf = 5, min_samples_split = 2, n_estimators = 100)\n",
        "randomForestXpLevel_model = randomForestXpLevel.fit(x_experiênce_level_train,y_experience_level_train)\n",
        "print('Train score: ',accuracy_score(y_experience_level_train,randomForestXpLevel_model.predict(x_experiênce_level_train)))\n",
        "print('Test score: ',accuracy_score(y_experience_level_test,randomForestXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "xktAPrOktkzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_experience_level_train,randomForestXpLevel_model.predict(x_experiênce_level_train)),accuracy_score(y_experience_level_test,randomForestXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "hoIIUWJ8uUBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_experience_level_train,randomForestXpLevel_model.predict(x_experiênce_level_train)),confusion_matrix(y_experience_level_test,randomForestXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "AuIvNWc8udqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_experience_level_train,randomForestXpLevel_model.predict(x_experiênce_level_train)),classification_report(y_experience_level_test,randomForestXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "Yr6dY81guiqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use now the SVM. Acuracy 87,6%\n"
      ],
      "metadata": {
        "id": "CS-HjkE8uo1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
        "    'tol':[0.0001,0.00001,0.000001],\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_experiênce_level_train, y_experience_level_train)\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "xB-YCGfBunXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVCXpLevel = SVC(C=0.1,gamma='scale',kernel='rbf',tol=0.0001)\n",
        "SVCXpLevel_model = SVCXpLevel.fit(x_experiênce_level_train,y_experience_level_train)\n",
        "print('Train score: ',accuracy_score(y_experience_level_train,SVCXpLevel_model.predict(x_experiênce_level_train)))\n",
        "print('Test score: ',accuracy_score(y_experience_level_test,SVCXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "Kgq_XhS-vkOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_experience_level_train,SVCXpLevel_model.predict(x_experiênce_level_train)),accuracy_score(y_experience_level_test,SVCXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "VnWqRmPS0n6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_experience_level_train,SVCXpLevel_model.predict(x_experiênce_level_train)),confusion_matrix(y_experience_level_test,SVCXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "nRykxlXi0scI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_experience_level_train,SVCXpLevel_model.predict(x_experiênce_level_train)),classification_report(y_experience_level_test,SVCXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "Fd6sEi1C0ytg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use K Neighbors.Accuracy 82,5%"
      ],
      "metadata": {
        "id": "XBMk-EPc1H1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_experiênce_level_train, y_experience_level_train)\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "BjB5B_Ck07Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kNeighborsXpLevel = KNeighborsClassifier(metric='euclidean',n_neighbors=9,p=1,weights='distance')\n",
        "kNeighborsXpLevel_model = kNeighborsXpLevel.fit(x_experiênce_level_train,y_experience_level_train)\n",
        "print('Train score: ',accuracy_score(y_experience_level_train,kNeighborsXpLevel_model.predict(x_experiênce_level_train)))\n",
        "print('Test score: ',accuracy_score(y_experience_level_test,kNeighborsXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "5Yn0SnKu10Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_experience_level_train,kNeighborsXpLevel_model.predict(x_experiênce_level_train)),accuracy_score(y_experience_level_test,kNeighborsXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "kbqKLM5a2DYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_experience_level_train,kNeighborsXpLevel_model.predict(x_experiênce_level_train)),confusion_matrix(y_experience_level_test,kNeighborsXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "Umws-v2a2Nxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_experience_level_train,kNeighborsXpLevel_model.predict(x_experiênce_level_train)),classification_report(y_experience_level_test,kNeighborsXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "6My68rin2Qvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use neural network using the skicit-larn.Accuracy: 84,1%"
      ],
      "metadata": {
        "id": "Ppw1md6E2ojq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (120,), (50, 50), (100, 50), (100, 100)],\n",
        "    'activation': ['relu', 'tanh', 'logistic'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'adaptive'],\n",
        "    'max_iter': [200, 300, 500],\n",
        "    'early_stopping': [True],\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=MLPClassifier(), param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(x_experiênce_level_train, y_experience_level_train)\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "id": "EJBk8Zi_2Xqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural_networkXpLevel = MLPClassifier(activation='tanh', alpha=0.0001, early_stopping=True, hidden_layer_sizes=(100, 100), learning_rate='constant', max_iter=300, solver='adam')\n",
        "neural_networkXpLevel_model = neural_networkXpLevel.fit(x_experiênce_level_train,y_experience_level_train)\n",
        "print('Train score: ',accuracy_score(y_experience_level_train,neural_networkXpLevel_model.predict(x_experiênce_level_train)))\n",
        "print('Test score: ',accuracy_score(y_experience_level_test,neural_networkXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "P0qTQ2NZ3V_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_experience_level_train,neural_networkXpLevel_model.predict(x_experiênce_level_train)),accuracy_score(y_experience_level_test,neural_networkXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "XVeMXiHDN3kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_experience_level_train,neural_networkXpLevel_model.predict(x_experiênce_level_train)),confusion_matrix(y_experience_level_test,neural_networkXpLevel_model.predict(x_experiênce_level_test))"
      ],
      "metadata": {
        "id": "ohoOKTGkOOtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_experience_level_train,neural_networkXpLevel_model.predict(x_experiênce_level_train)),classification_report(y_experience_level_test,neural_networkXpLevel_model.predict(x_experiênce_level_test)))"
      ],
      "metadata": {
        "id": "aRayJDpGOXdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try create a neural network with tensorflow"
      ],
      "metadata": {
        "id": "x0yWPCUtRg8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(hidden_layer_sizes=(50,), activation='relu', dropout_rate=0.0, learning_rate=0.001):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    for units in hidden_layer_sizes:\n",
        "        model.add(Dense(units, activation=activation))\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "FYEIBbW0OeBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'dropout_rate': [0.0, 0.2, 0.5],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'epochs': [50, 100],\n",
        "    'batch_size': [16, 32, 64],\n",
        "}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)"
      ],
      "metadata": {
        "id": "zKXJL3piVlXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}